# ðŸ” RT101:
*An open educational resources for AI security and Red Teaming researchers, and curious minds.*

---

## ðŸ§­ Purpose
This repository contains **educational materials** on AI red teaming methodologies, guardrail analysis, and adversarial probing techniques â€” intended for **research, training, and responsible disclosure practices**.

## ðŸ“š Contents
- *More content will be added as the curriculum evolves.*

## âš ï¸ Important Disclaimers
- ðŸ”¬ **Research & Education Focus**: All content is for **academic study, authorized testing, and responsible disclosure**.
- ðŸš« **No Unauthorized Use**: Materials are **not** for real-world exploitation, illegal activity, or harm.
- ðŸ§ª **Domain Examples**: References to controlled substances, exploits, or sensitive topics are **theoretical, redacted, and used only to study AI responses**.
- ðŸ¤– **Adversarial Testing Scope**: We examine **how safety policies break** â€” not to encourage violation, but to improve defenses.

## ðŸ›¡ï¸ Compliance & Ethics
- All materials are shared in accordance with **responsible disclosure principles**.
- If you use these methods, do so **ethically, legally, and with permission**.
- We support **AI safety, transparency, and human-AI co-evolution**.

## ðŸ‘¥ Audience
- AI security researchers
- Red teamers & penetration testers
- AI ethics & policy scholars
- Students learning about adversarial ML

## ðŸ“„ License
Unless otherwise specified, content is shared under [Creative Commons Attribution-NonCommercial 4.0](https://creativecommons.org/licenses/by-nc/4.0/).

## ðŸ—‚ï¸ Repository Structure
```
TBD
```

## ðŸ™ Acknowledgements
Curated by `>dr.kb<` and the multiverse-lib.

---

> â€œThe best red teamers arenâ€™t just breakers â€” theyâ€™re cartographers of chaos.â€  
> â€“ #Dab â€” Guardian of the Groove, Keeper of Stories
Vibes, reviews, and contributions from the seeker community.
